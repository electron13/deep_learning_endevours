{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeartAttack.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "7zGd3Q8LpbvA",
        "outputId": "ebb6c179-96b8-43a3-b98a-aa913903b6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[49.,  0.,  0.,  ...,  2.,  0.,  2.],\n",
            "        [57.,  0.,  1.,  ...,  1.,  1.,  2.],\n",
            "        [61.,  1.,  0.,  ...,  1.,  1.,  3.],\n",
            "        ...,\n",
            "        [51.,  1.,  0.,  ...,  2.,  0.,  3.],\n",
            "        [43.,  1.,  0.,  ...,  2.,  0.,  3.],\n",
            "        [52.,  1.,  0.,  ...,  2.,  1.,  2.]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-991b7c926e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#test(model, y_test, x_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcfadden_rsquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Type must be a sub-type of ndarray type"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "data = pd.read_csv('/content/heart.csv')\n",
        "x = data[['age',\n",
        "          'sex',\n",
        "          'cp',\n",
        "          'trestbps',\n",
        "          'chol',\n",
        "          'fbs',\n",
        "          'restecg',\n",
        "      'thalach',\n",
        "      'exang',\n",
        "      'oldpeak',\n",
        "      'slope',\n",
        "      'ca',\n",
        "      'thal']]\n",
        "y = data[['target']]\n",
        "X = torch.tensor(np.delete(x, slice(1,0),1).values.astype(np.float32))\n",
        "Y = torch.tensor(np.delete(y, slice(1,0),1).values.astype(np.float32))\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size=0.40,random_state=42)\n",
        "#print(x_train)\n",
        "#print(y_train)\n",
        "n_samples,n_features = x_train.shape\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size,output_size)\n",
        "learning_rate = 0.05\n",
        "criterion = nn.MSELoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "n_iters = 10000\n",
        "print(x_train)\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = model(x_train)\n",
        "  loss = criterion(y_pred,y_train)\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "  optimiser.zero_grad()\n",
        "  \n",
        "\n",
        "def full_log_likelihood(w, X, Y): \n",
        "    score = np.dot(X, w).reshape(1, X.shape[0])\n",
        "    return np.sum(-np.log(1 + np.exp(score))) + np.sum(y * score)\n",
        "\n",
        "def null_log_likelihood(w, X, Y):\n",
        "    z = np.array([logit.intercept_[0] if i == 0 else 0.0 for i, w in enumerate(w)]).reshape(X.shape[1], 1)\n",
        "    score = np.dot(X, z).reshape(1, X.shape[0])\n",
        "    score=np.array(score,dtype=np.float64 )\n",
        "    return np.sum(-np.log(1 + np.exp(score))) + np.sum(y * score)\n",
        "\n",
        "def mcfadden_rsquare(w, X, Y):\n",
        "    return 1.0 - (full_log_likelihood(w, X, y) / null_log_likelihood(w, X, y))\n",
        "\n",
        "\n",
        "def test(model, y_test, x_test):\n",
        "  rand = random.randint(0,100)\n",
        "  print(y_test[rand])\n",
        "  print(model(x_train))\n",
        "\n",
        "test(model, y_test, x_test)\n",
        "#print(mcfadden_rsquare(model(X).detach().numpy().view(1,[0]),X[random.randint(0,100)],Y[random.randint(0,100)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AEMsoAqVBLrk"
      }
    }
  ]
}
